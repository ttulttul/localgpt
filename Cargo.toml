[package]
name = "localgpt"
version = "0.1.2"
edition = "2021"
description = "A local device focused AI assistant with persistent markdown memory, autonomous heartbeat tasks, and semantic search. Single binary, no runtime dependencies."
license = "Apache-2.0"
repository = "https://github.com/localgpt-app/localgpt"
homepage = "https://localgpt.app"
documentation = "https://github.com/localgpt-app/localgpt/blob/main/README.md"
readme = "README.md"
keywords = ["ai", "assistant", "llm", "memory", "local"]
categories = ["command-line-utilities", "text-processing"]

[features]
default = ["desktop"]
# Desktop GUI (eframe/egui). Disable for headless/server/Docker builds.
desktop = ["eframe"]
# GGUF embedding model support via llama.cpp (requires C++ compiler)
gguf = ["llama-cpp-2"]

[dependencies]
# Async runtime
tokio = { version = "1.43", features = ["full"] }

# CLI
clap = { version = "4.5", features = ["derive", "env"] }

# HTTP client for LLM APIs
reqwest = { version = "0.12", features = ["json", "stream"] }

# HTTP server
axum = { version = "0.8", features = ["ws", "macros"] }
tower-http = { version = "0.6", features = ["cors", "trace"] }

# Database
rusqlite = { version = "0.32", features = ["bundled", "functions", "vtab", "load_extension"] }

# Vector search extension for SQLite
sqlite-vec = "0.1.7-alpha.2"

# Local embeddings (default - no API key needed)
fastembed = "5.8"

# GGUF embeddings via llama.cpp (optional, requires C++ compiler)
llama-cpp-2 = { version = "0.1", optional = true }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
serde_yaml = "0.9"
json5 = "0.4"
toml = "0.8"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }

# File watching
notify = "7.0"
notify-debouncer-mini = "0.5"

# Token counting
tiktoken-rs = "0.6"

# Static file embedding for Web UI
rust-embed = { version = "8", features = ["compression"] }
mime_guess = "2.0"

# Utilities
chrono = { version = "0.4", features = ["serde"] }
directories = "6.0"
thiserror = "2.0"
anyhow = "1.0"
uuid = { version = "1.11", features = ["v4"] }
async-trait = "0.1"
futures = "0.3"
tokio-stream = "0.1"
async-stream = "0.3"
shellexpand = "3.1"
glob = "0.3"
base64 = "0.22"
regex = "1"
once_cell = "1"
fs2 = "0.4"
rand = "0.8"

# Telegram bot
teloxide = { version = "0.17", features = ["macros"] }

# Desktop GUI (optional â€” disable with --no-default-features for headless builds)
eframe = { version = "0.30", optional = true, default-features = false, features = [
    "default_fonts",
    "glow",
    "persistence",
    "x11",
    "wayland",
] }

# Unix daemonization (optional, only for daemon mode)
[target.'cfg(unix)'.dependencies]
daemonize = "0.5"
sha2 = "0.10"
rustyline = "17.0.2"

[dev-dependencies]
tempfile = "3.14"
mockall = "0.13"

[[bin]]
name = "localgpt"
path = "src/main.rs"

[profile.release]
lto = true
codegen-units = 1
strip = true
